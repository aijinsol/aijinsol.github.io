---
title: "[DL] Image Classification DL ëª¨ë¸ ë§Œë“¤ê¸° - ê°œ vs ê³ ì–‘ì´ êµ¬ë¶„"
excerpt: "(Kaggle) ê°œ ê³ ì–‘ì´ êµ¬ë¶„ DL í”„ë¡œì íŠ¸"
categories:
 - DeepLearning
tags:
  - keras
  - codding apple
last_modified_at: 2022-09-29
---

> Kaggle í”„ë¡œì íŠ¸ì˜ ì‹¤ì „ ë°ì´í„°ë¡œ í”„ë¡œì íŠ¸ ì§„í–‰í•´ë³´ê¸° <br>
> [Kaggle: Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)

| ê°œ ê³ ì–‘ì´ êµ¬ë¶„ DL í”„ë¡œì íŠ¸

```python
import os
import shutil
import tensorflow as tf


# Data Download
os.environ['KAGGLE_CONFIG_DIR'] = '/Users/jinsolkim/.kaggle/'

!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition

!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d .
!unzip -q train.zip -d .

os.mkdir('./dataset')
os.mkdir('./dataset/cat')
os.mkdir('./dataset/dog')

for i in os.listdir('./train/'):
    if 'cat' in i:
        shutil.copyfile('./train/' + i, './dataset/cat/' + i)
    if 'dog' in i:
        shutil.copyfile('./train/' + i, './dataset/dog/' + i)

# Pre-processing
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    './dataset/',
    image_size=(64,64),
    batch_size=64,
    subset='training',
    validation_split=0.2,
    seed=100
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    './dataset/',
    image_size=(64,64),
    batch_size=64,
    subset='validation',
    validation_split=0.2,
    seed=100
)

def pre_process(i, ans):
    i = tf.cast(i/255.0, tf.float32)
    return i, ans

train_ds = train_ds.map(pre_process)
val_ds = val_ds.map(pre_process)

# Model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(train_ds, validation_data=val_ds, epochs=5)
```

<br>

# 1. Kaggle Data Download

+ Kaggle í™ˆí˜ì´ì§€ì—ì„œ `My Account > API - Create New API Token` í´ë¦­
+ ë‹¤ìš´ë¡œë“œ ëœ kaggle.json íŒŒì¼ì„ `~/.kaggle/`ì— ìœ„ì¹˜ì‹œê¸°í‚¤ (Mac ê¸°ì¤€)

```python
import os

os.environ['KAGGLE_CONFIG_DIR'] = '/Users/jinsolkim/.kaggle/'

!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition
```

ë‹¤ìš´ë¡œë“œ ëœ zipíŒŒì¼ ì••ì¶• í’€ê¸°
```python
!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d .
!unzip -q train.zip -d .
```

ì´ë¯¸ì§€ íŒŒì¼ ê°¯ìˆ˜ í™•ì¸
```python
print(len(os.listdir('./train/')))
```

<br>

# 2. Data Preprocessing

<div class="notice--info" markdown="1">
ğŸ’¡ Image classificationí•  ë•ŒëŠ” `dataset` í´ë” ì•ˆì— ê° ì¹´í…Œê³ ë¦¬ ë³„ë¡œ í´ë” ë§Œë“¤ì–´ì„œ í•´ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹ ì˜®ê²¨ë†“ê¸°!! (í•­ìƒ!â­ï¸)
</div>

## 1) Dataset

dataset í´ë” ë§Œë“¤ê¸°

```python
os.mkdir('./dataset')
os.mkdir('./dataset/cat')
os.mkdir('./dataset/dog')
```

ê°œ vs ê³ ì–‘ì´ íŒŒì¼ íŒŒì¼ ë¶„ë¥˜í•´ì„œ dataset í´ë”ë¡œ ë³µì‚¬
```python
import shutil

for i in os.listdir('./train/'): # íŒŒì¼ëª… (ex. cat.5077.jpg)
    if 'cat' in i:
        shutil.copyfile('./train/' + i, './dataset/cat/' + i)
    if 'dog' in i:
        shutil.copyfile('./train/' + i, './dataset/dog/' + i) 
```

<br>

## 2) Image to Tensor

ì´ë¯¸ì§€ ìˆ«ìë¡œ ë³€í™˜í•˜ê¸°

```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    './dataset/',
    image_size=(64,64),
    batch_size=64,
    subset='training',
    validation_split=0.2,
    seed=100
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    './dataset/',
    image_size=(64,64),
    batch_size=64,
    subset='validation',
    validation_split=0.2,
    seed=100
)

print(train_ds)
print(val_ds)


------------------------------------------------------------
Found 25000 files belonging to 2 classes.
Using 20000 files for training.
Found 25000 files belonging to 2 classes.
Using 5000 files for validation.
<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>
<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>
```

+ `tf.keras.preprocessing.image_dataset_from_directory()` : í´ë” ë‚´ ì´ë¯¸ì§€ë“¤ì„ ë°”ë¡œ ìˆ«ìí™”ëœ datasetìœ¼ë¡œ ë§Œë“¤ì–´ ì¤€ë‹¤.
+ `image_size=(64,64)` : ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 64x64 pixelë¡œ ì••ì¶•
+ `batch_size=64` : ì´ë¯¸ì§€ 2ë§Œì¥ì„ ëª¨ë¸ì— í•œë²ˆì— ë„£ì§€ ì•Šê³  batch ìˆ«ìë§Œí¼ ë„£ë„ë¡
+ `subset='training'` : train dataset ì´ë¦„ ë¶™ì´ê¸°. ì•„ë˜ `validation_split`ì— ë”°ë¼ ì´ ë°ì´í„°ëŠ” ì „ì²´ ë°ì´í„°ì˜ 80%)
    `subset='validation'` : validation dataset ì´ë¦„ ë¶™ì´ê¸°. ì•„ë˜ `validation_split`ì— ë”°ë¼ ì´ ë°ì´í„°ëŠ” ì „ì²´ ë°ì´í„°ì˜ 80%)
+ `validation_split=0.2`
    + datasetì—ì„œ validation dataset split
    + `train_ds` ë¸”ë¡ ë°‘ì— `val_ds`ë„ ë˜‘ê°™ì€ í˜•íƒœë¡œ í•œë²ˆ ë” ì¨ì¤˜ì•¼ í•œë‹¤.
    + `train_ds` ë¸”ë¡ì—ì„œëŠ” `subset='training'`, `val_ds `ë¸”ë¡ì—ì„œëŠ” `subset='validation'` ì¨ì¤˜ì„œ ê°ê° ë¬´ìŠ¨ ë°ì´í„°ë¥¼ ì˜ë¯¸í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ì£¼ê¸°!
+ `train_ds`ëŠ” `( (xxx), (yyy) )` í˜•íƒœ. ì¦‰, `( (ì´ë¯¸ì§€ 2ë§Œê°œ), (ì •ë‹µ 2ë§Œê°œ) )`.

<br>

## 3) Image Pre-processing

ë°ì´í„° 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ scaling
```python
def pre_process(i, ans):
    i = tf.cast(i/255.0, tf.float32)
    return i, ans

train_ds = train_ds.map(pre_process)
val_ds = val_ds.map(pre_process)
```

ë°ì´í„°ì…‹ í™•ì¸
```python
import matplotlib.pyplot as plt

for i, ans in train_ds.take(1):
    print(i.shape)
    print(i)
    print(ans.shape)
    print(ans)
    plt.imshow(i[0].numpy().astype('uint8'))
    plt.show()


------------------------------------------------------------
(64, 64, 64, 3)
tf.Tensor(
[[[[0.23100491 0.21568628 0.20318627]
   [0.1858226  0.1740579  0.13876379]
   [0.18834636 0.17266008 0.16089538]
   ...
   [0.16947381 0.1069738  0.07952283]
   [0.13084023 0.11123239 0.08770297]
   [0.13333334 0.11372549 0.09019608]]

  [[0.23925781 0.22393918 0.21143919]
   [0.1872664  0.17550169 0.14020757]
   [0.18532859 0.16964231 0.15787761]
   ...
   [0.16032858 0.10784314 0.07745098]
   [0.1420343  0.12242647 0.09889706]
   [0.13725491 0.11764706 0.09411765]]

  [[0.25       0.22683823 0.23284313]
   [0.21454887 0.184892   0.16246553]
   [0.23345588 0.18639706 0.1942402 ]
   ...
   [0.1764706  0.14901961 0.11764706]
   [0.17058824 0.12745099 0.11960784]
   [0.17634805 0.13321078 0.12536764]]
...
(64,)
tf.Tensor(
[0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1
 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0], shape=(64,), dtype=int32)
```

+ `i = tf.cast( i/255.0, tf.float32 )`
    + (ë°”ë¡œ `i = i/255.0` ë¡œ í•˜ë©´ ì¢‹ê² ì§€ë§Œ) tensorì´ë¯€ë¡œ `tf.cast` ì‚¬ìš©
    + `tf.float32` : ë§Œì•½ì„ ìœ„í•´ì„œ ìë£Œí˜• ê°•ì œ

<br>

# 3. Model

```python
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),    # 128ê°œì˜ ë…¸ë“œ ì¤‘ 20% ì œê±°
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()


------------------------------------------------------------
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4 (Conv2D)           (None, 64, 64, 32)        896       
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 32, 32, 32)       0         
 2D)                                                             
                                                                 
 conv2d_5 (Conv2D)           (None, 32, 32, 64)        18496     
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (None, 16, 16, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 16, 16, 128)       73856     
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 8, 8, 128)        0         
 2D)                                                             
                                                                 
 flatten_3 (Flatten)         (None, 8192)              0         
                                                                 
 dense_5 (Dense)             (None, 128)               1048704   
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 dense_6 (Dense)             (None, 1)                 129       
                                                                 
=================================================================
Total params: 1,142,081
Trainable params: 1,142,081
Non-trainable params: 0
_________________________________________________________________
```
```python
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(train_ds, validation_data=val_ds, epochs=5)
```

+ Dropout ë ˆì´ì–´
    + overfitting ì™„í™” ê°€ëŠ¥
    + ìœ— ë ˆì´ì–´ì˜ ë…¸ë“œë¥¼ ì¼ë¶€ ì œê±°í•´ì¤€ë‹¤.
    + ex) `tf.keras.layers.Dropout(0.2)` : ìœ— ë ˆì´ì–´ì˜ ë…¸ë“œ ì¤‘ 20% ì œê±°í•´ì£¼ì„¸ìš”.

<br>

# 4. Results

+ ë°ì´í„° ì „ì²˜ë¦¬ 0~1 scaling í–ˆì„ ë•Œ vs ì•ˆ í–ˆì„ ë•Œ ëª¨ë¸ ì„±ëŠ¥ ì°¨ì´
    + ë°ì´í„° ì „ì²˜ë¦¬í•˜ì§€ ì•Šì•˜ì„ ë•Œ
    ```bash
    Epoch 1/5
    313/313 [==============================] - 10s 26ms/step - loss: 2.5032 - accuracy: 0.5839 - val_loss: 0.6012 - val_accuracy: 0.6806
    Epoch 2/5
    313/313 [==============================] - 8s 25ms/step - loss: 0.5912 - accuracy: 0.6789 - val_loss: 0.6017 - val_accuracy: 0.6486
    Epoch 3/5
    313/313 [==============================] - 8s 25ms/step - loss: 0.5473 - accuracy: 0.7165 - val_loss: 0.5435 - val_accuracy: 0.7136
    Epoch 4/5
    313/313 [==============================] - 8s 25ms/step - loss: 0.5230 - accuracy: 0.7341 - val_loss: 0.5169 - val_accuracy: 0.7546
    Epoch 5/5
    313/313 [==============================] - 8s 25ms/step - loss: 0.4988 - accuracy: 0.7554 - val_loss: 0.5080 - val_accuracy: 0.7536
    ```
    + ë°ì´í„° ì „ì²˜ë¦¬í–ˆì„ ë•Œ (0~1 scaling)
    ```bash
    Epoch 1/5
    313/313 [==============================] - 8s 23ms/step - loss: 0.5454 - accuracy: 0.7229 - val_loss: 0.5101 - val_accuracy: 0.7456
    Epoch 2/5
    313/313 [==============================] - 8s 24ms/step - loss: 0.4639 - accuracy: 0.7816 - val_loss: 0.4541 - val_accuracy: 0.7910
    Epoch 3/5
    313/313 [==============================] - 7s 23ms/step - loss: 0.4262 - accuracy: 0.8047 - val_loss: 0.4284 - val_accuracy: 0.7974
    Epoch 4/5
    313/313 [==============================] - 7s 23ms/step - loss: 0.3850 - accuracy: 0.8260 - val_loss: 0.3896 - val_accuracy: 0.8176
    Epoch 5/5
    313/313 [==============================] - 7s 23ms/step - loss: 0.3539 - accuracy: 0.8416 - val_loss: 0.3769 - val_accuracy: 0.8208
    ```
+ Input dataì˜ ìˆ«ìë¥¼ 0~1 ì‚¬ì´ë¡œ ì••ì¶•í•˜ë©´ â‡’ ì—°ì‚° ì†ë„ ë¹¨ë¼ì§€ê³ (ìµœì ì˜ wê°’ ë¹¨ë¦¬ ì°¾ëŠ”ë‹¤), accuracy ì¦ê°€.
+ val_acc ì•½ 85%ê°€ ì´ ëª¨ë¸ì—ì„œì˜ ìµœëŒ€ accuracy.
    + ë¬¸ì œëŠ” ë°ì´í„°ì˜ í€„ë¦¬í‹°.
    + ê²°êµ­, ë°ì´í„°ì˜ ì „ì²˜ë¦¬(ì–‘, ì§ˆ)ê°€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°ì— í° íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¨ë‹¤!


# Reference
+ [ì½”ë”©ì• í”Œ - ë¬¸ê³¼ì—¬ë„ ìƒê´€ì—†ë‹¤ Tensorflow ë”¥ëŸ¬ë‹ AI ê¸°ì´ˆë¶€í„° ì‹¤ë¬´ê¹Œì§€](https://codingapple.com/course/python-deep-learning/)