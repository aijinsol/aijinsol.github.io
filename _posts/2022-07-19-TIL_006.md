---
title: "[TIL_006] 2022-07-19"
excerpt: ""
categories:
  - TIL
tags:
last_modified_at: 2022-07-19
---

# 1. Learning Rate(학습률) 조절

## 1) LR 조절 방법
+ Local minimum에 효율적으로 도달할 수 있도록, 너무 크지도 작지도 않은 적절한 learning rate의 세팅이 중요
+ 보통 0.01부터 시작하여 cost함수의 값을 관찰하며 learning rate의 값을 조절
  + 결과가 발산한다면 LR 줄이기, 학습시간이 너무 길다면 LR 키우기
+ 초기에는 높은 learning rate로 학습시키다 점점 learning rate를 감소시키는 방법이 가장 효과적

## 2) too big
+ 그래프에서 하강하는 폭이 너무 커서 데이터가 무질서하게 이탈함
+ 학습이 이루어지지 않을 뿐만 아니라, 최저점에 도달하는 것을 넘어서 반대 방향의 그래프에 도달할만큼 overshooting 발생 가능성이 커진다. (최저점에 수렴하지 못함)

## 3) just right
+ 적절한 학습 곡선의 형태를 그린다.

## 3) too small
+ 최저점에 도달하는 데까지 소요되는 시간이 너무 길어지고, global minimum이 아닌 local minimum에 빠질 가능성이 있다. (최저점에 도달하지 못함)

![image01](/assets/images/2022-07-19-til_01.png){: .align-center}{: width="70%" height="70%"}

<br>

![image02](/assets/images/2022-07-19-til_02.png){: .align-center}{: width="70%" height="70%"}

<br>

# 2. Overfitting 줄이기

+ `Overfitting`은 train dataset에 너무 적합해진 현상을 의미
+ overfitting 방지법
  + 더 많은 train dataset으로 학습
  + 변수의 수 줄이기
  + regularization
    + `regularization`이란 데이터를 표현하는 모델을 최대한 덜 울퉁불퉁하게 표현하는 것을 의미

![image03](/assets/images/2022-07-19-til_03.png){: .align-center}{: width="70%" height="70%"}
*Regularization*

<br>

# Reference
+ [learning rate graph](https://bioinformaticsandme.tistory.com/130)
+ [learning rate](https://bioinformaticsandme.tistory.com/130)
+ [overfitting](https://computer-nerd.tistory.com/13)

<br>
